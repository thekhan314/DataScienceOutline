{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(\n",
    "        token.text, \n",
    "        token.pos_, # Part of speech the token is\n",
    "        token.dep_ # Syntacti dependency\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the spacy module in the cell above we loaded a **model** and named it `nlp`.<br>Next we created a **Doc** object by applying the model to our text, and named it `doc`.<br>spaCy also builds a companion **Vocab** object that we'll cover in later sections.<br>The **Doc** object that holds the processed text is our focus here.\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see what components currently live in the pipeline. In later sections we'll learn how to disable components and add new ones as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x237cb1e8f98>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x237cb2852b0>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x237cb285360>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spans & Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spans \n",
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In upcoming lectures we'll see how to create Span objects using `Span()`. This will allow us to assign additional information to the Span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Sentences\n",
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`. Later we'll write our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "The first step in processing text is to split up all the component parts (words & punctuation) into \"tokens\". These tokens are annotated inside the Doc object to contain descriptive information. We'll go into much more detail on tokenization in an upcoming lecture. For now, let's look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "n't ADV neg\n",
      "   SPACE \n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't   looking into startups anymore.\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `isn't` has been split into two tokens. spaCy recognizes both the root verb `is` and the negation attached to it. Notice also that both the extended whitespace and the period at the end of the sentence are assigned their own tokens.\n",
    "\n",
    "It's important to note that even though `doc2` contains processed information about each token, it also retains the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't   looking into startups anymore."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-of-Speech Tagging (POS)\n",
    "The next step after splitting the text up into tokens is to assign parts of speech. In the above example, `Tesla` was recognized to be a ***proper noun***. Here some statistical modeling is required. For example, words that follow \"the\" are typically nouns.\n",
    "\n",
    "For a full list of POS Tags visit https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a *morphological analysis* to words. The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'. Further, the lemma of 'meeting' might be 'meet' or 'meeting' depending on its use in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "am \t VERB \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t ADP \t 16950148841647037698 \t because\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t ADP \t 10066841407251338481 \t since\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Going a step beyond tokens, *named entities* add another layer of context. The language model recognizes that certain words are organizational names while others are locations, and still other combinations relate to money, dates, etc. Named entities are accessible through the `ents` property of a `Doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Note how two tokens combine to form the entity `Hong Kong`, and three tokens combine to form the monetary entity:  `$6 million`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc8.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER) is an important machine learning tool applied to Natural Language Processing.<br>We'll do a lot more with it in an upcoming section. For more info on **named entities** visit https://spacy.io/usage/linguistic-features#named-entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Additional Token Attributes\n",
    "We'll see these again in upcoming lectures. For now we just want to illustrate some of the other information that spaCy assigns to tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape – capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "# Lemmas (the base form of the word):\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Dependencies\n",
    "We also looked at the syntactic dependencies assigned to each token. `Tesla` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
    "\n",
    "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
    "<br>A good explanation of typed dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full name of a tag use `spacy.explain(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ner = Named Entity Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Noun Chunks\n",
    "Similar to `Doc.ents`, `Doc.noun_chunks` are another object property. *Noun chunks* are \"base noun phrases\" – flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun – for example, in [Sheb Wooley's 1958 song](https://en.wikipedia.org/wiki/The_Purple_People_Eater), a *\"one-eyed, one-horned, flying, purple people-eater\"* would be one long noun chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
    "\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "a one-eyed, one-horned, flying, purple people-eater\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
    "\n",
    "for chunk in doc11.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at additional noun_chunks components besides `.text` in an upcoming section.<br>For more info on **noun_chunks** visit https://spacy.io/usage/linguistic-features#noun-chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "Words like \"a\" and \"the\" appear so frequently that they don't require tagging as thoroughly as nouns, verbs and modifiers. We call these *stop words*, and they can be filtered from the text to be processed. spaCy holds a built-in list of some 305 English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see if a word is a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To add a stop word\n",
    "There may be times when you wish to add a stop word to the default set. Perhaps you decide that `'btw'` (common shorthand for \"by the way\") should be considered a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase!\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>When adding stop words, always use lowercase. Lexemes are converted to lowercase before being added to **vocab**.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####111 To remove a stop word\n",
    "Alternatively, you may decide that `'beyond'` should not be considered a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "\n",
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule-based Matching\n",
    "spaCy offers a rule-matching tool called `Matcher` that allows you to build a library of token patterns, then match those patterns against a Doc object to return a list of found matches. You can match on any part of the token including text and annotations, and you can add multiple patterns to the same matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Here `matcher` is an object that pairs to the current `Vocab` object. We can add and remove specific named matchers to `matcher` as needed.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating patterns\n",
    "In literature, the phrase 'solar power' might appear as one word or two, with or without a hyphen. In this section we'll develop a matcher named 'SolarPower' that finds all three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this down:\n",
    "* `pattern1` looks for a single token whose lowercase text reads 'solarpower'\n",
    "* `pattern2` looks for two adjacent tokens that read 'solar' and 'power' in that order\n",
    "* `pattern3` looks for three adjacent tokens, with a middle token that can be any punctuation.<font color=green>*</font>\n",
    "\n",
    "<font color=green>\\* Remember that single spaces are not tokenized, so they don't count as punctuation.</font>\n",
    "<br>Once we define our patterns, we pass them into `matcher` with the name 'SolarPower', and set *callbacks* to `None` (more on callbacks later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the matcher to a Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matcher` returns a list of tuples. Each tuple contains an ID for the match, with start & end tokens that map to the span `doc[start:end]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `match_id` is simply the hash value of the `string_ID` 'SolarPower'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting pattern options and quantifiers\n",
    "You can make token rules optional by passing an `'OP':'*'` argument. This lets us streamline our patterns list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the patterns:\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'power'}]\n",
    "\n",
    "# Remove the old patterns to avoid duplication:\n",
    "matcher.remove('SolarPower')\n",
    "\n",
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "matcher.add('SolarPower', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This found both two-word patterns, with and without the hyphen!\n",
    "\n",
    "The following quantifiers can be passed to the `'OP'` key:\n",
    "<table><tr><th>OP</th><th>Description</th></tr>\n",
    "\n",
    "<tr ><td><span >\\!</span></td><td>Negate the pattern, by requiring it to match exactly 0 times</td></tr>\n",
    "<tr ><td><span >?</span></td><td>Make the pattern optional, by allowing it to match 0 or 1 times</td></tr>\n",
    "<tr ><td><span >\\+</span></td><td>Require the pattern to match 1 or more times</td></tr>\n",
    "<tr ><td><span >\\*</span></td><td>Allow the pattern to match zero or more times</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be careful with lemmas!\n",
    "If we wanted to match on both 'solar power' and 'solar powered', it might be tempting to look for the *lemma* of 'powered' and expect it to be 'power'. This is not always the case! The lemma of the *adjective* 'powered' is still 'powered':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LEMMA': 'power'}] # CHANGE THIS PATTERN\n",
    "\n",
    "# Remove the old patterns to avoid duplication:\n",
    "matcher.remove('SolarPower')\n",
    "\n",
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "matcher.add('SolarPower', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Solar-powered energy runs solar-powered cars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The matcher found the first occurrence because the lemmatizer treated 'Solar-powered' as a verb, but not the second as it considered it an adjective.<br>For this case it may be better to set explicit token patterns.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solarpowered'}]\n",
    "pattern4 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'powered'}]\n",
    "\n",
    "# Remove the old patterns to avoid duplication:\n",
    "matcher.remove('SolarPower')\n",
    "\n",
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3, pattern4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 5, 8)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other token attributes\n",
    "Besides lemmas, there are a variety of token attributes we can use to determine matching rules:\n",
    "<table><tr><th>Attribute</th><th>Description</th></tr>\n",
    "\n",
    "<tr ><td><span >`ORTH`</span></td><td>The exact verbatim text of a token</td></tr>\n",
    "<tr ><td><span >`LOWER`</span></td><td>The lowercase form of the token text</td></tr>\n",
    "<tr ><td><span >`LENGTH`</span></td><td>The length of the token text</td></tr>\n",
    "<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>Token text consists of alphanumeric characters, ASCII characters, digits</td></tr>\n",
    "<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>Token text is in lowercase, uppercase, titlecase</td></tr>\n",
    "<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token is punctuation, whitespace, stop word</td></tr>\n",
    "<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Token text resembles a number, URL, email</td></tr>\n",
    "<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>The token's simple and extended part-of-speech tag, dependency label, lemma, shape</td></tr>\n",
    "<tr ><td><span >`ENT_TYPE`</span></td><td>The token's entity label</td></tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token wildcard\n",
    "You can pass an empty dictionary `{}` as a wildcard to represent **any token**. For example, you might want to retrieve hashtags without knowing what might follow the `#` character:\n",
    ">`[{'ORTH': '#'}, {}]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/regex_cheat_sheet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Matches\n",
    "There are a few ways to fetch the text surrounding a match. The simplest is to grab a slice of tokens from the doc that is wider than the match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[665:685]  # Note that the fifth match starts at doc3[673]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "against institutions.[66] His policies became widely known as \"trickle-down economics\", due to the significant"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[2975:2995]  # The sixth match starts at doc3[2985]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to first apply the `sentencizer` to the Doc, then iterate through the sentences to the match point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35\n"
     ]
    }
   ],
   "source": [
    "# Build a list of sentences\n",
    "sents = [sent for sent in doc3.sents]\n",
    "\n",
    "# In the next section we'll see that sentences contain start and end token values:\n",
    "print(sents[0].start, sents[0].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-stimulus economics.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the sentence list until the sentence end value exceeds a match start value:\n",
    "for sent in sents:\n",
    "    if matches[4][1] < sent.end:  # this is the fifth match, that starts at doc3[673]\n",
    "        print(sent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### PhraseMatcher\n",
    "In the above section we used token patterns to perform rule-based matching. An alternative - and often more efficient - method is to match on terminology lists. In this case we use PhraseMatcher to create a Doc object from a list of phrases, and pass that into `matcher` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports, reset nlp\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PhraseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we're going to import a Wikipedia article on *Reaganomics*<br>\n",
    "Source: https://en.wikipedia.org/wiki/Reaganomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TextFiles/reaganomics.txt', encoding='utf8') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a list of match phrases:\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']\n",
    "\n",
    "# Next, convert each phrase to a Doc object:\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "# Pass each Doc object into matcher (note the use of the asterisk!):\n",
    "matcher.add('VoodooEconomics', None, *phrase_patterns)\n",
    "\n",
    "# Build a list of matches:\n",
    "matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3473369816841043438, 41, 45),\n",
       " (3473369816841043438, 49, 53),\n",
       " (3473369816841043438, 54, 56),\n",
       " (3473369816841043438, 61, 65),\n",
       " (3473369816841043438, 673, 677),\n",
       " (3473369816841043438, 2985, 2989)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (match_id, start, end)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the dependency parse\n",
    "Run the cell below to import displacy and display the dependency graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1370\" height=\"357.0\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optional `'distance'` argument sets the distance between tokens. If the distance is made too small, text that appears beneath short arrows may become too compressed to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Creating Visualizations Outside of Jupyter\n",
    "If you're using another Python IDE or writing a script, you can choose to have spaCy serve up html separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Serving on port 5000...\n",
      "    Using the 'dep' visualizer\n",
      "\n",
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'This is a sentence.')\n",
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**After running the cell above, click the link below to view the dependency parse**:</font>\n",
    "\n",
    "http://127.0.0.1:5000\n",
    "<br><br>\n",
    "<font color=red>**To shut down the server and return to jupyter**, interrupt the kernel either through the **Kernel** menu above, by hitting the black square on the toolbar, or by typing the keyboard shortcut `Esc`, `I`, `I`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(some_text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "stopwords_list += list(string.punctuation)\n",
    "\n",
    "stopwords_list += [str(i) for i in range(0,10)]\n",
    "\n",
    "macbeth_words_stopped = [word for word in macbeth_tokens if word not in stopwords_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.FreqDist()\n",
    "\n",
    "macbeth_stopped_freqdist = FreqDist(macbeth_words_stopped)\n",
    "\n",
    "macbeth_stopped_freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Often when searching text for a certain keyword, it helps if the search returns variations of the word. For instance, searching for \"boat\" might also return \"boats\" and \"boating\". Here, \"boat\" would be the **stem** for [boat, boater, boating, boats].\n",
    "\n",
    "Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached. This works fairly well in most cases, but unfortunately English has many exceptions where a more sophisticated process is required. In fact, spaCy doesn't include a stemmer, opting instead to rely entirely on lemmatization. For those interested, there's some background on this decision [here](https://github.com/explosion/spaCy/issues/327). We discuss the virtues of *lemmatization* in the next section.\n",
    "\n",
    "Instead, we'll use another popular NLP tool called **nltk**, which stands for *Natural Language Toolkit*. For more information on nltk visit https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter Stemmer\n",
    "\n",
    "One of the most common - and effective - stemming tools is [*Porter's Algorithm*](https://tartarus.org/martin/PorterStemmer/) developed by Martin Porter in [1980](https://tartarus.org/martin/PorterStemmer/def.txt). The algorithm employs five phases of word reduction, each with its own set of mapping rules. In the first phase, simple suffix mapping rules are defined, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stemming1.png](../stemming1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a given set of stemming rules only one rule is applied, based on the longest suffix S1. Thus, `caresses` reduces to `caress` but not `cares`.\n",
    "\n",
    "More sophisticated phases consider the length/complexity of the word before applying a rule. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stemming1.png](../stemming2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `m>0` describes the \"measure\" of the stem, such that the rule is applied to all but the most basic stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the toolkit and the full Porter Stemmer library\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Note how the stemmer recognizes \"runner\" as a noun, not a verb form or participle. Also, the adverbs \"easily\" and \"fairly\" are stemmed to the unusual root \"easili\" and \"fairli\"</font>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer\n",
    "This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since **nltk** uses the name SnowballStemmer, we'll use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "# words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=green>In this case the stemmer performed the same as the Porter Stemmer, with the exception that it handled the stem of \"fairly\" more appropriately with \"fair\"</font>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciKit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing                                                                                                                                                                                                                                                                                                         y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    " \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the word is used often in many other documents, it is not unique, and therefore probably not too useful if we wanted to figure out how this document is unique in relation to other documents. \n",
    "\n",
    "- Conversely, if a word is used many times in a document, but rarely in all the other documents we are considering, then it is likely a good indicator for telling us that this word is important to the document in question.  \n",
    "\n",
    "The formula TF-IDF uses to determine the weights of each term in a document is **_Term Frequency_** multiplied by **_Inverse Document Frequency_**, where the formula for Term Frequency is:\n",
    "\n",
    "$$\\large Term\\ Frequency(t) = \\frac{number\\ of\\ times\\ t\\ appears\\ in\\ a\\ document} {total\\ number\\ of\\ terms\\ in\\ the\\ document} $$\n",
    "\n",
    "The formula for Inverse Document Frequency is:  \n",
    "<br>  \n",
    "<br>\n",
    "$$\\large  IDF(t) =  log_e(\\frac{Total\\ Number\\ of\\ Documents}{Number\\ of\\ Documents\\ with\\ t\\ in\\ it})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vect = TfidfVectorizer()\n",
    "\n",
    "df3_tfvect = new_vect.fit_transform(df3_selection['fd_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Naïve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne_object_3d = TSNE(n_components=3)\n",
    "transformed_data_3d = t_sne_object_3d.fit_transform(tf_idf_vals_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "    # Max df: ignore words that have really high doc frequency\n",
    "        # between 0 and 1\n",
    "    # Min df: words that show up a minimum number of times\n",
    "        # integer value is raw num of docs that must have word for it to be counted\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=7,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning LDA topic to original documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab Vocab of words\n",
    "# found in cv objectr\n",
    "cv.get_feature_names()  # Hold instaces of every word. \n",
    "                        # List of all words in all docs (1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab topics from LDA\n",
    "\n",
    "LDA.components_    # Numpy array wtih probabilites for each word\n",
    "                    # Rows are topics, cols are names\n",
    "    \n",
    "LDA.components[0].argsort() # returns the indices that would sort row\n",
    "                            # smallest to largest\n",
    "\n",
    "\n",
    "top_word_indices = single_topic.argsort()[-10:]\n",
    "\n",
    "# use indexes to slice cv list. \n",
    "\n",
    "for index in top_word_indices:\n",
    "    print(cv.get_feature_names()[index])\n",
    "    \n",
    "# OR: Use list comprehension\n",
    "\n",
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add topics to original \n",
    "\n",
    "topic_results = lda.transform(dtm) # fit to the vectorized matrix \n",
    "                                    # that the lda was fit on\n",
    "                # returns array with rows = documents, columns = prob doc belogns to a doc\n",
    "\n",
    "topic_results[0].argmax() # returns topic of highest probability\n",
    "\n",
    "# add topic as column\n",
    "npr['Topic'] = topic_results.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorizatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
