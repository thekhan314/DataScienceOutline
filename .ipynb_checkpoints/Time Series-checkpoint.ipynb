{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Convert to Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data['Date'] = pd.to_datetime(temp_data['Date'], format='%d/%m/%y')\n",
    "temp_data.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_monthly = temp_data.resample('MS')\n",
    "month_mean = temp_monthly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_bidaily = temp_data.resample('12H').asfreq()\n",
    "temp_bidaily.head()\n",
    "\n",
    "temp_bidaily_fill = temp_bidaily.ffill()\n",
    "temp_bidaily_fill.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the timeseries to contain data after year 1990 \n",
    "post_90 = CO2['1990':]\n",
    "\n",
    "# Retrieve the data between 1st Jan 1990 to 1st Jan 1991\n",
    "mid_slice = CO2['1990-01':'1991-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the .fillna() method can be used along with methods like .bfill() of .ffill() as an argument/criterion for filling in missing values . .bfill() (backward filling) looks for the next valid entry in the time series and fills the gaps with this value. Similarly, .ffill() can be used to copy forward the previous valid entry of the time series (as demonstrated above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2_final = CO2.fillna('bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plot\n",
    "\n",
    "\n",
    "# Dot Plot\n",
    "nyse.plot(figsize = (20,6), style = '.b');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping for a given time interval by averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nyse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fd57b5720f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use pandas grouper to group values using annual frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myear_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnyse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnyse_annual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nyse' is not defined"
     ]
    }
   ],
   "source": [
    "# Use pandas grouper to group values using annual frequency\n",
    "year_groups = nyse.groupby(pd.Grouper(freq ='A'))\n",
    "\n",
    "nyse_annual = pd.DataFrame()\n",
    "\n",
    "for yr, group in year_groups:\n",
    "    nyse_annual[yr.year] = group.values.ravel()\n",
    "    \n",
    "# Plot the yearly groups as subplots\n",
    "nyse_annual.plot(figsize = (13,8), subplots=True, legend=True);\n",
    "\n",
    "# to plot on one plot\n",
    "nyse_annual.plot(figsize = (15,5), subplots=False, legend=True);\n",
    "\n",
    "nyse_annual.boxplot(figsize = (12,7));\n",
    "\n",
    "# HEatmap. Transpose first\n",
    "year_matrix = nyse_annual.T\n",
    "plt.matshow(year_matrix, interpolation=None, aspect='auto', cmap=plt.cm.Spectral_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_mean = ts.rolling(window=8, center=False).mean()\n",
    "roll_std = ts.rolling(window=8, center=False).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,7))\n",
    "plt.plot(ts, color='blue', label='Original')\n",
    "plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "plt.plot(roll_std, color='black', label = 'Rolling Std')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean & Standard Deviation')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dickey Fuller Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dickey-Fuller test is a statistical test for testing stationarity. \n",
    "\n",
    "The null-hypothesis for the test is that \n",
    "    - <b> the time series is not stationary</b> . \n",
    "    \n",
    "    So if the test statistic is less than the critical value, we reject the null hypothesis and say that the series is stationary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "dftest = adfuller(ts)\n",
    "\n",
    "# Extract and display test results in a user friendly manner\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Log or Sq Root or Cube Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.log(final_series), index=index)\n",
    "\n",
    "data = pd.Series(np.sqrt(final_series), index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtract rolling mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minus_roll_mean = data - roll_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Rolling Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas ewm() to calculate Exponential Weighted Moving Average\n",
    "exp_roll_mean = data.ewm(halflife=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the moving average from the original data\n",
    "data_minus_exp_roll_mean = data - exp_roll_mean\n",
    "data_minus_exp_roll_mean.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this technique, we take the difference of an observation at a particular time instant with that at the previous instant (i.e. a so-called 1-period \"lag\").\n",
    "\n",
    "This mostly works pretty well in improving stationarity. First-order differencing can be done in Pandas using the .diff() method with periods=1 (denoting a 1-period lag). Details on .diff() can be found here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = data.diff(periods=1)\n",
    "data_diff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(np.log(ts))\n",
    "\n",
    "# Gather the trend, seasonality, and residuals \n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_shift_1 = diet.shift(periods=1)\n",
    "\n",
    "lag_1 = pd.concat([diet_shift_1, diet], axis=1)\n",
    "\n",
    "lag_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Auto Correlation Function\n",
    "plt.figure(figsize=(12,5))\n",
    "pd.plotting.autocorrelation_plot(diet);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with differencing\n",
    "gtrends_diff = gtrends.diff(periods=1)\n",
    "\n",
    "diet_diff = gtrends_diff[['Diet']].dropna()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "pd.plotting.autocorrelation_plot(diet_diff);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Auto COrrelation\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "\n",
    "plot_pacf(diet, lags=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA Models in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,3))\n",
    "plot_acf(series, ax=ax, lags=40);\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,3))\n",
    "plot_pacf(series, ax=ax, lags=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ARMA\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Instantiate an AR(1) model to the simulated data\n",
    "mod_arma = ARMA(series, order=(1,0))\n",
    "\n",
    "res_arma = mod_arma.fit()\n",
    "res_arma.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARMA(1,0), ARMA(2,2) and ARMA(2,1) all seem to have decent fits with significant parameters. \n",
    "Depending on whether you pick AIC or BIC as a model selection criterion, \n",
    "your result may vary. In this situation, you'd generally go for a model with fewer parameters, \n",
    "so ARMA(1,0) seems fine. Note that we have a relatively short time series, \n",
    "which can lead to a more difficult model selection process.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
